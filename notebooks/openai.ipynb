{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854488f2",
   "metadata": {},
   "source": [
    "# üöÄ OpenAI Python SDK 101\n",
    "\n",
    "In this notebook we‚Äôll learn how to interact with Large Language Models (LLMs) directly using the **OpenAI Python SDK**.  \n",
    "This is the **first time** we‚Äôre exploring API interactions, so we‚Äôll build up gradually:\n",
    "\n",
    "1. **Initialize** the client with your API key.  \n",
    "2. **Minimal call** to the API (Responses API).  \n",
    "3. Use **Chat Completions** for system + user roles.  \n",
    "4. Explore **temperature** (randomness) and **top_p** (nucleus sampling).  \n",
    "5. Add **system prompts** to guide behavior.  \n",
    "6. Try **streaming tokens** (like ChatGPT typing).  \n",
    "7. Get **JSON/structured outputs** with schemas.  \n",
    "8. Handle **errors, timeouts, and retries** gracefully.\n",
    "\n",
    "By the end, you‚Äôll know how to **call an LLM safely and flexibly** using just the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844e5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf239a",
   "metadata": {},
   "source": [
    "### API key\n",
    "- Set your OpenAI API key as an environment variable:  \n",
    "  `export OPENAI_API_KEY=\"sk-...\"` (macOS/Linux) or `setx OPENAI_API_KEY \"sk-...\"` (Windows, new terminal required).  \n",
    "- In Colab: use `os.environ[\"OPENAI_API_KEY\"] = \"...\"` (for demos only).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c9cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature controls the randomness of predictions by scaling the probabilities of possible outcomes, while top_p (nucleus sampling) limits the selection to a subset of the most probable options, ensuring a balance between randomness and coherence in the generated text.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Python SDK v1 style\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Minimal \"Responses API\" call (recommended by OpenAI for new projects)\n",
    "# Docs: https://platform.openai.com/docs/guides/text  and Responses vs Chat Completions\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",  # choose any available text-capable model\n",
    "    input=\"In one sentence, explain the difference between temperature and top_p for sampling.\"\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff892c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Overfitting occurs when a machine learning model learns the noise or random fluctuations in the training data rather than the underlying pattern, leading to poor generalization to new, unseen data.\n",
      "\n",
      "- **Symptoms**: Indicators of overfitting include a model that performs significantly better on training data compared to validation/test data, often showing high accuracy on the former and low accuracy on the latter.\n",
      "\n",
      "- **Solutions**: Techniques to mitigate overfitting include using simpler models (regularization), reducing the number of features, employing cross-validation, and using techniques like dropout in neural networks.\n"
     ]
    }
   ],
   "source": [
    "# Using Chat Completions (still widely used & supported)\n",
    "chat = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise teaching assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me 3 bullet points about overfitting.\"}\n",
    "    ]\n",
    ")\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5dddecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can reverse a string in Python using slicing. Here's a simple example:\n",
      "\n",
      "```python\n",
      "original_string = \"Hello, World!\"\n",
      "reversed_string = original_string[::-1]\n",
      "print(reversed_string)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```\n",
      "!dlroW ,olleH\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python tutor who answers with short code examples.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Show how to reverse a string in Python.\"}\n",
    "]\n",
    "r = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=0.2)\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553e975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a quiet little town nestled between rolling hills, there lived a cat named Whiskers and a dog named Max. Though they lived in neighboring houses, they had never met. Whiskers was a sleek, silver tabby with piercing green eyes, known for her grace and independence. Max, on the other hand, was a big, fluffy golden retriever with a heart as big as his bark, always eager for companionship and adventure.\n",
      "\n",
      "One sunny afternoon, Whiskers decided to explore beyond her usual territory. She ventured into the backyard of Max's home, drawn by the tantalizing scent of blooming flowers and the sound of a rustling breeze. As she crept through the tall grass, she spotted Max chasing a butterfly, his tail wagging furiously.\n",
      "\n",
      "Curious, Whiskers perched herself on a low fence post to watch. Max, noticing her, skidded to a stop, panting with excitement. \"Hello there! I‚Äôm Max! Want to play?\" he barked, his voice filled with enthusiasm.\n",
      "\n",
      "Whiskers flicked her tail, unsure. ‚ÄúPlay? With you? I‚Äôm not so sure about that,‚Äù she replied, her voice smooth and aloof. Cats were known for their independence, and she wasn‚Äôt one to frolic about like a dog.\n",
      "\n",
      "But Max wasn‚Äôt discouraged. ‚ÄúCome on! It‚Äôll be fun! I can show you how to chase butterflies!‚Äù He leapt into the air, trying to catch the elusive creature, but it danced away, teasingly just out of reach.\n",
      "\n",
      "Whiskers let out a soft chuckle, amused by his antics. ‚ÄúYou think you can catch it? Watch this.‚Äù With a graceful leap, she sprang off the fence and, using her agility, darted after the butterfly, weaving through the flowers. Max watched in awe as she moved with such fluidity.\n",
      "\n",
      "Impressed, Max barked, ‚ÄúWow! You‚Äôre fast! Can you teach me how to do that?‚Äù\n",
      "\n",
      "Whiskers paused, considering for a moment. ‚ÄúAlright, but only if you show me how to dig a hole. I‚Äôve always wanted to see what‚Äôs underneath the soil.‚Äù\n",
      "\n",
      "‚ÄúDeal!‚Äù Max wagged his tail eagerly, and together they began an afternoon of playful learning. Whiskers taught Max how to stalk and pounce, while Max showed her the joy of digging and the thrill of uncovering hidden treasures like old bones and shiny rocks.\n",
      "\n",
      "As the sun began to set, painting the sky in hues of gold and pink, the two newfound friends lay side by side, exhausted but happy. Whiskers looked over at Max, her heart warming. ‚ÄúYou know, I didn‚Äôt think I would enjoy playing with a dog, but this was fun.‚Äù\n",
      "\n",
      "Max grinned, his tongue lolling out. ‚ÄúAnd I never thought a cat could be so cool! We should do this again!‚Äù\n",
      "\n",
      "From that day on, Whiskers and Max became the best of friends, spending their afternoons exploring the garden, chasing butterflies, and sharing secrets under the shade of the old oak tree. They discovered that despite their differences, they complemented each other perfectly, proving that friendship knows no bounds.\n",
      "\n",
      "And so, in their little town, the cat and the dog created a bond that would last a lifetime, showing everyone that sometimes, the most unexpected friendships are the most beautiful of all.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import stdout\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a cat and a dog.\"}],\n",
    "    temperature=0.7,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if hasattr(event, \"choices\"):\n",
    "        delta = event.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            stdout.write(delta.content)\n",
    "stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7efd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary(topic='Transformers in NLP', key_points=['**Revolutionary Architecture:** \\nTransformers have revolutionized the field of Natural Language Processing (NLP) by introducing a novel architecture that relies on self-attention mechanisms. This allows models to weigh the importance of different words in a sentence, capturing long-range dependencies more effectively than previous models like RNNs and LSTMs.', '**Scalability and Efficiency:** \\nTransformers are highly scalable and can be trained on large datasets, making them suitable for a wide range of NLP tasks. Their parallelizable structure allows for efficient training on modern hardware, leading to faster processing times and the ability to handle vast amounts of data.', '**Foundation for Pre-trained Models:** \\nTransformers serve as the backbone for many state-of-the-art pre-trained language models, such as BERT, GPT, and T5. These models leverage the transformer architecture to achieve high performance on various NLP tasks, including text classification, translation, and question answering, by fine-tuning on specific datasets.'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    topic: str\n",
    "    key_points: List[str]\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    temperature=0,\n",
    "    response_format=Summary,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Topic: Transformers in NLP. Give 3 key points.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsed = completion.choices[0].message.parsed\n",
    "parsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
